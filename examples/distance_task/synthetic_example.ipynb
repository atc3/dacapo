{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dacapo\n",
    "\n",
    "DaCapo is a framework that allows for easy configuration and execution of established machine learning techniques on arbitrarily large volumes of multi-dimensional images.\n",
    "\n",
    "DaCapo has 4 major configurable components:\n",
    "1. **dacapo.datasplits.DataSplit**\n",
    "\n",
    "2. **dacapo.tasks.Task**\n",
    "\n",
    "3. **dacapo.architectures.Architecture**\n",
    "\n",
    "4. **dacapo.trainers.Trainer**\n",
    "\n",
    "These are then combined in a single **dacapo.experiments.Run** that includes your starting point (whether you want to start training from scratch or continue off of a previously trained model) and stopping criterion (the number of iterations you want to train)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Environment setup\n",
    "If you have not already done so, you will need to install DaCapo. You can do this by first creating a new environment and then installing DaCapo using pip.\n",
    "\n",
    "```bash\n",
    "conda create -n dacapo python=3.10\n",
    "conda activate dacapo\n",
    "```\n",
    "\n",
    "Then, you can install DaCapo using pip, via GitHub:\n",
    "\n",
    "```bash\n",
    "pip install git+https://github.com/janelia-cellmap/dacapo.git\n",
    "```\n",
    "\n",
    "Or you can clone the repository and install it locally:\n",
    "\n",
    "```bash\n",
    "git clone https://github.com/janelia-cellmap/dacapo.git\n",
    "cd dacapo\n",
    "pip install -e .\n",
    "```\n",
    "\n",
    "Be sure to select this environment in your Jupyter notebook or JupyterLab."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Config Store\n",
    "To define where the data goes, create a dacapo.yaml configuration file either in `~/.config/dacapo/dacapo.yaml` or in `./dacapo.yaml`. Here is a template:\n",
    "\n",
    "```yaml\n",
    "mongodbhost: mongodb://dbuser:dbpass@dburl:dbport/\n",
    "mongodbname: dacapo\n",
    "runs_base_dir: /path/to/my/data/storage\n",
    "```\n",
    "The runs_base_dir defines where your on-disk data will be stored. The mongodbhost and mongodbname define the mongodb host and database that will store your cloud data. If you want to store everything on disk, replace mongodbhost and mongodbname with a single type `files` and everything will be saved to disk:\n",
    "\n",
    "```yaml\n",
    "type: files\n",
    "runs_base_dir: /path/to/my/data/storage\n",
    "```\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dacapo.store.create_store import create_config_store\n",
    "\n",
    "config_store = create_config_store()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from examples.random_source_pipeline import random_source_pipeline\n",
    "import gunpowder as gp\n",
    "import neuroglancer\n",
    "import numpy as np\n",
    "from IPython.display import IFrame\n",
    "from scipy.ndimage import gaussian_filter\n",
    "\n",
    "pipeline, request = random_source_pipeline(input_shape=(120, 120, 120))\n",
    "\n",
    "\n",
    "def batch_generator():\n",
    "    with gp.build(pipeline):\n",
    "        while True:\n",
    "            yield pipeline.request_batch(request)\n",
    "\n",
    "\n",
    "batch_gen = batch_generator()\n",
    "batch = next(batch_gen)\n",
    "raw_array = batch.arrays[gp.ArrayKey(\"RAW\")]\n",
    "labels_array = batch.arrays[gp.ArrayKey(\"LABELS\")]\n",
    "\n",
    "\n",
    "labels_data = labels_array.data\n",
    "raw_data = raw_array.data\n",
    "\n",
    "neuroglancer.set_server_bind_address(\"0.0.0.0\")\n",
    "viewer = neuroglancer.Viewer()\n",
    "with viewer.txn() as state:\n",
    "    state.showSlices = False\n",
    "    state.layers[\"segs\"] = neuroglancer.SegmentationLayer(\n",
    "        # segments=[str(i) for i in np.unique(data[data > 0])], # this line will cause all objects to be selected and thus all meshes to be generated...will be slow if lots of high res meshes\n",
    "        source=neuroglancer.LocalVolume(\n",
    "            data=labels_data,\n",
    "            dimensions=neuroglancer.CoordinateSpace(\n",
    "                names=[\"z\", \"y\", \"x\"],\n",
    "                units=[\"nm\", \"nm\", \"nm\"],\n",
    "                scales=labels_array.spec.voxel_size,\n",
    "            ),\n",
    "            # voxel_offset=ds.roi.begin / ds.voxel_size,\n",
    "        ),\n",
    "        segments=np.unique(labels_data[labels_data > 0]),\n",
    "    )\n",
    "\n",
    "    state.layers[\"raw\"] = neuroglancer.ImageLayer(\n",
    "        source=neuroglancer.LocalVolume(\n",
    "            data=raw_data,\n",
    "            dimensions=neuroglancer.CoordinateSpace(\n",
    "                names=[\"z\", \"y\", \"x\"],\n",
    "                units=[\"nm\", \"nm\", \"nm\"],\n",
    "                scales=raw_array.spec.voxel_size,\n",
    "            ),\n",
    "        ),\n",
    "    )\n",
    "\n",
    "IFrame(src=viewer, width=1500, height=600)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Datasplit\n",
    "Where can you find your data? What format is it in? Does it need to be normalized? What data do you want to use for validation?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dacapo.experiments.datasplits.datasets.arrays import (\n",
    "    BinarizeArrayConfig,\n",
    "    CropArrayConfig,\n",
    "    ConcatArrayConfig,\n",
    "    IntensitiesArrayConfig,\n",
    "    MissingAnnotationsMaskConfig,\n",
    "    ResampledArrayConfig,\n",
    "    ZarrArrayConfig,\n",
    ")\n",
    "from dacapo.experiments.datasplits import TrainValidateDataSplitConfig\n",
    "from dacapo.experiments.datasplits.datasets import RawGTDatasetConfig\n",
    "from pathlib import PosixPath\n",
    "from funlib.geometry import Roi\n",
    "\n",
    "datasplit_config = TrainValidateDataSplitConfig(\n",
    "    name=\"example_synthetic_datasplit_config\",\n",
    "    train_configs=[\n",
    "        RawGTDatasetConfig(\n",
    "            name=\"example_raw_data\",\n",
    "            weight=1,\n",
    "            raw_config=IntensitiesArrayConfig(\n",
    "                name=\"jrc_mus-liver_s1_raw\",\n",
    "                source_array_config=ZarrArrayConfig(\n",
    "                    name=\"jrc_mus-liver_raw_uint8\",\n",
    "                    file_name=PosixPath(\n",
    "                        \"/nrs/cellmap/data/jrc_mus-liver/jrc_mus-liver.n5\"\n",
    "                    ),\n",
    "                    dataset=\"volumes/raw/s1\",\n",
    "                    snap_to_grid=(16, 16, 16),\n",
    "                    axes=None,\n",
    "                ),\n",
    "                min=0.0,\n",
    "                max=255.0,\n",
    "            ),\n",
    "            gt_config=BinarizeArrayConfig(\n",
    "                name=\"jrc_mus-liver_124_mito_proxisome_many_8nm_gt\",\n",
    "                source_array_config=ResampledArrayConfig(\n",
    "                    name=\"jrc_mus-liver_124_gt_resampled_8nm\",\n",
    "                    source_array_config=ZarrArrayConfig(\n",
    "                        name=\"jrc_mus-liver_124_gt\",\n",
    "                        file_name=PosixPath(\n",
    "                            \"/nrs/cellmap/zouinkhim/data/tmp_data_v3/jrc_mus-liver/jrc_mus-liver.n5\"\n",
    "                        ),\n",
    "                        dataset=\"volumes/groundtruth/crop124/labels//all\",\n",
    "                        snap_to_grid=(16, 16, 16),\n",
    "                        axes=None,\n",
    "                    ),\n",
    "                    upsample=(0, 0, 0),\n",
    "                    downsample=(2, 2, 2),\n",
    "                    interp_order=False,\n",
    "                ),\n",
    "                groupings=[(\"mito\", [3, 4, 5]), (\"peroxisome\", [47, 48])],\n",
    "                background=0,\n",
    "            ),\n",
    "            mask_config=MissingAnnotationsMaskConfig(\n",
    "                name=\"jrc_mus-liver_124_mito_proxisome_many_8nm_mask\",\n",
    "                source_array_config=ResampledArrayConfig(\n",
    "                    name=\"jrc_mus-liver_124_gt_resampled_8nm\",\n",
    "                    source_array_config=ZarrArrayConfig(\n",
    "                        name=\"jrc_mus-liver_124_gt\",\n",
    "                        file_name=PosixPath(\n",
    "                            \"/nrs/cellmap/zouinkhim/data/tmp_data_v3/jrc_mus-liver/jrc_mus-liver.n5\"\n",
    "                        ),\n",
    "                        dataset=\"volumes/groundtruth/crop124/labels//all\",\n",
    "                        snap_to_grid=(16, 16, 16),\n",
    "                        axes=None,\n",
    "                    ),\n",
    "                    upsample=(0, 0, 0),\n",
    "                    downsample=(2, 2, 2),\n",
    "                    interp_order=False,\n",
    "                ),\n",
    "                groupings=[(\"mito\", [3, 4, 5]), (\"peroxisome\", [47, 48])],\n",
    "            ),\n",
    "            sample_points=None,\n",
    "        ),\n",
    "        RawGTDatasetConfig(\n",
    "            name=\"jrc_mus-liver_125_mito_proxisome_many_8nm\",\n",
    "            weight=1,\n",
    "            raw_config=IntensitiesArrayConfig(\n",
    "                name=\"jrc_mus-liver_s1_raw\",\n",
    "                source_array_config=ZarrArrayConfig(\n",
    "                    name=\"jrc_mus-liver_raw_uint8\",\n",
    "                    file_name=PosixPath(\n",
    "                        \"/nrs/cellmap/data/jrc_mus-liver/jrc_mus-liver.n5\"\n",
    "                    ),\n",
    "                    dataset=\"volumes/raw/s1\",\n",
    "                    snap_to_grid=(16, 16, 16),\n",
    "                    axes=None,\n",
    "                ),\n",
    "                min=0.0,\n",
    "                max=255.0,\n",
    "            ),\n",
    "            gt_config=BinarizeArrayConfig(\n",
    "                name=\"jrc_mus-liver_125_mito_proxisome_many_8nm_gt\",\n",
    "                source_array_config=ResampledArrayConfig(\n",
    "                    name=\"jrc_mus-liver_125_gt_resampled_8nm\",\n",
    "                    source_array_config=ZarrArrayConfig(\n",
    "                        name=\"jrc_mus-liver_125_gt\",\n",
    "                        file_name=PosixPath(\n",
    "                            \"/nrs/cellmap/zouinkhim/data/tmp_data_v3/jrc_mus-liver/jrc_mus-liver.n5\"\n",
    "                        ),\n",
    "                        dataset=\"volumes/groundtruth/crop125/labels//all\",\n",
    "                        snap_to_grid=(16, 16, 16),\n",
    "                        axes=None,\n",
    "                    ),\n",
    "                    upsample=(0, 0, 0),\n",
    "                    downsample=(2, 2, 2),\n",
    "                    interp_order=False,\n",
    "                ),\n",
    "                groupings=[(\"mito\", [3, 4, 5]), (\"peroxisome\", [47, 48])],\n",
    "                background=0,\n",
    "            ),\n",
    "            mask_config=MissingAnnotationsMaskConfig(\n",
    "                name=\"jrc_mus-liver_125_mito_proxisome_many_8nm_mask\",\n",
    "                source_array_config=ResampledArrayConfig(\n",
    "                    name=\"jrc_mus-liver_125_gt_resampled_8nm\",\n",
    "                    source_array_config=ZarrArrayConfig(\n",
    "                        name=\"jrc_mus-liver_125_gt\",\n",
    "                        file_name=PosixPath(\n",
    "                            \"/nrs/cellmap/zouinkhim/data/tmp_data_v3/jrc_mus-liver/jrc_mus-liver.n5\"\n",
    "                        ),\n",
    "                        dataset=\"volumes/groundtruth/crop125/labels//all\",\n",
    "                        snap_to_grid=(16, 16, 16),\n",
    "                        axes=None,\n",
    "                    ),\n",
    "                    upsample=(0, 0, 0),\n",
    "                    downsample=(2, 2, 2),\n",
    "                    interp_order=False,\n",
    "                ),\n",
    "                groupings=[(\"mito\", [3, 4, 5]), (\"peroxisome\", [47, 48])],\n",
    "            ),\n",
    "            sample_points=None,\n",
    "        ),\n",
    "    ],\n",
    "    validate_configs=[\n",
    "        RawGTDatasetConfig(\n",
    "            name=\"jrc_mus-liver_145_mito_proxisome_many_8nm\",\n",
    "            weight=1,\n",
    "            raw_config=IntensitiesArrayConfig(\n",
    "                name=\"jrc_mus-liver_s1_raw\",\n",
    "                source_array_config=ZarrArrayConfig(\n",
    "                    name=\"jrc_mus-liver_raw_uint8\",\n",
    "                    file_name=PosixPath(\n",
    "                        \"/nrs/cellmap/data/jrc_mus-liver/jrc_mus-liver.n5\"\n",
    "                    ),\n",
    "                    dataset=\"volumes/raw/s1\",\n",
    "                    snap_to_grid=(16, 16, 16),\n",
    "                    axes=None,\n",
    "                ),\n",
    "                min=0.0,\n",
    "                max=255.0,\n",
    "            ),\n",
    "            gt_config=BinarizeArrayConfig(\n",
    "                name=\"jrc_mus-liver_145_mito_proxisome_many_8nm_gt\",\n",
    "                source_array_config=ResampledArrayConfig(\n",
    "                    name=\"jrc_mus-liver_145_gt_resampled_8nm\",\n",
    "                    source_array_config=ZarrArrayConfig(\n",
    "                        name=\"jrc_mus-liver_145_gt\",\n",
    "                        file_name=PosixPath(\n",
    "                            \"/nrs/cellmap/zouinkhim/data/tmp_data_v3/jrc_mus-liver/jrc_mus-liver.n5\"\n",
    "                        ),\n",
    "                        dataset=\"volumes/groundtruth/crop145/labels//all\",\n",
    "                        snap_to_grid=(16, 16, 16),\n",
    "                        axes=None,\n",
    "                    ),\n",
    "                    upsample=(0, 0, 0),\n",
    "                    downsample=(2, 2, 2),\n",
    "                    interp_order=False,\n",
    "                ),\n",
    "                groupings=[(\"mito\", [3, 4, 5]), (\"peroxisome\", [47, 48])],\n",
    "                background=0,\n",
    "            ),\n",
    "            mask_config=MissingAnnotationsMaskConfig(\n",
    "                name=\"jrc_mus-liver_145_mito_proxisome_many_8nm_mask\",\n",
    "                source_array_config=ResampledArrayConfig(\n",
    "                    name=\"jrc_mus-liver_145_gt_resampled_8nm\",\n",
    "                    source_array_config=ZarrArrayConfig(\n",
    "                        name=\"jrc_mus-liver_145_gt\",\n",
    "                        file_name=PosixPath(\n",
    "                            \"/nrs/cellmap/zouinkhim/data/tmp_data_v3/jrc_mus-liver/jrc_mus-liver.n5\"\n",
    "                        ),\n",
    "                        dataset=\"volumes/groundtruth/crop145/labels//all\",\n",
    "                        snap_to_grid=(16, 16, 16),\n",
    "                        axes=None,\n",
    "                    ),\n",
    "                    upsample=(0, 0, 0),\n",
    "                    downsample=(2, 2, 2),\n",
    "                    interp_order=False,\n",
    "                ),\n",
    "                groupings=[(\"mito\", [3, 4, 5]), (\"peroxisome\", [47, 48])],\n",
    "            ),\n",
    "            sample_points=None,\n",
    "        ),\n",
    "        RawGTDatasetConfig(\n",
    "            name=\"jrc_mus-liver-zon-1_386_mito_proxisome_many_8nm\",\n",
    "            weight=1,\n",
    "            raw_config=IntensitiesArrayConfig(\n",
    "                name=\"jrc_mus-liver-zon-1_s1_raw\",\n",
    "                source_array_config=ZarrArrayConfig(\n",
    "                    name=\"jrc_mus-liver-zon-1_raw_uint8\",\n",
    "                    file_name=PosixPath(\n",
    "                        \"/nrs/cellmap/data/jrc_mus-liver-zon-1/jrc_mus-liver-zon-1.n5\"\n",
    "                    ),\n",
    "                    dataset=\"em/fibsem-uint8/s1\",\n",
    "                    snap_to_grid=(16, 16, 16),\n",
    "                    axes=None,\n",
    "                ),\n",
    "                min=0.0,\n",
    "                max=255.0,\n",
    "            ),\n",
    "            gt_config=CropArrayConfig(\n",
    "                name=\"jrc_mus-liver-zon-1_386_8nm_gt_cropped\",\n",
    "                source_array_config=ConcatArrayConfig(\n",
    "                    name=\"jrc_mus-liver-zon-1_386_8nm_gt\",\n",
    "                    channels=[\"mito\", \"peroxisome\"],\n",
    "                    source_array_configs={\n",
    "                        \"peroxisome\": BinarizeArrayConfig(\n",
    "                            name=\"jrc_mus-liver-zon-1_386_peroxisome_8nm_binarized\",\n",
    "                            source_array_config=ResampledArrayConfig(\n",
    "                                name=\"jrc_mus-liver-zon-1_386_peroxisome_resampled_8nm\",\n",
    "                                source_array_config=ZarrArrayConfig(\n",
    "                                    name=\"jrc_mus-liver-zon-1_386_peroxisome\",\n",
    "                                    file_name=PosixPath(\n",
    "                                        \"/nrs/cellmap/zouinkhim/data/tmp_data_v3/jrc_mus-liver-zon-1/jrc_mus-liver-zon-1.n5\"\n",
    "                                    ),\n",
    "                                    dataset=\"volumes/groundtruth/crop386/labels//peroxisome\",\n",
    "                                    snap_to_grid=(16, 16, 16),\n",
    "                                    axes=None,\n",
    "                                ),\n",
    "                                upsample=(4, 4, 4),\n",
    "                                downsample=(0, 0, 0),\n",
    "                                interp_order=False,\n",
    "                            ),\n",
    "                            groupings=[(\"peroxisome\", [])],\n",
    "                            background=0,\n",
    "                        )\n",
    "                    },\n",
    "                    default_config=None,\n",
    "                ),\n",
    "                roi=Roi([145600, 59200, 147200], [3200, 3200, 6400]),\n",
    "            ),\n",
    "            mask_config=CropArrayConfig(\n",
    "                name=\"jrc_mus-liver-zon-1_386_8nm_mask_cropped\",\n",
    "                source_array_config=CropArrayConfig(\n",
    "                    name=\"jrc_mus-liver-zon-1_386_8nm_gt_cropped\",\n",
    "                    source_array_config=ConcatArrayConfig(\n",
    "                        name=\"jrc_mus-liver-zon-1_386_8nm_gt\",\n",
    "                        channels=[\"mito\", \"peroxisome\"],\n",
    "                        source_array_configs={\n",
    "                            \"peroxisome\": BinarizeArrayConfig(\n",
    "                                name=\"jrc_mus-liver-zon-1_386_peroxisome_8nm_binarized\",\n",
    "                                source_array_config=ResampledArrayConfig(\n",
    "                                    name=\"jrc_mus-liver-zon-1_386_peroxisome_resampled_8nm\",\n",
    "                                    source_array_config=ZarrArrayConfig(\n",
    "                                        name=\"jrc_mus-liver-zon-1_386_peroxisome\",\n",
    "                                        file_name=PosixPath(\n",
    "                                            \"/nrs/cellmap/zouinkhim/data/tmp_data_v3/jrc_mus-liver-zon-1/jrc_mus-liver-zon-1.n5\"\n",
    "                                        ),\n",
    "                                        dataset=\"volumes/groundtruth/crop386/labels//peroxisome\",\n",
    "                                        snap_to_grid=(16, 16, 16),\n",
    "                                        axes=None,\n",
    "                                    ),\n",
    "                                    upsample=(4, 4, 4),\n",
    "                                    downsample=(0, 0, 0),\n",
    "                                    interp_order=False,\n",
    "                                ),\n",
    "                                groupings=[(\"peroxisome\", [])],\n",
    "                                background=0,\n",
    "                            )\n",
    "                        },\n",
    "                        default_config=None,\n",
    "                    ),\n",
    "                    roi=Roi([145600, 59200, 147200], [3200, 3200, 6400]),\n",
    "                ),\n",
    "                roi=Roi([145600, 59200, 147200], [3200, 3200, 6400]),\n",
    "            ),\n",
    "            sample_points=None,\n",
    "        ),\n",
    "    ],\n",
    ")\n",
    "\n",
    "config_store.store_datasplit_config(datasplit_config)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task\n",
    "What do you want to learn? An instance segmentation? If so, how? Affinities,\n",
    "Distance Transform, Foreground/Background, etc. Each of these tasks are commonly learned\n",
    "and evaluated with specific loss functions and evaluation metrics. Some tasks may\n",
    "also require specific non-linearities or output formats from your model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dacapo.experiments.tasks import DistanceTaskConfig\n",
    "\n",
    "task_config = DistanceTaskConfig(\n",
    "    name=\"example_distances_8nm_mito_proxisome_many\",\n",
    "    channels=[\"mito\", \"peroxisome\"],\n",
    "    clip_distance=80.0,\n",
    "    tol_distance=80.0,\n",
    "    scale_factor=160.0,\n",
    "    mask_distances=True,\n",
    "    clipmin=0.05,\n",
    "    clipmax=0.95,\n",
    ")\n",
    "config_store.store_task_config(task_config)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Architecture\n",
    "\n",
    "The setup of the network you will train. Biomedical image to image translation often utilizes a UNet, but even after choosing a UNet you still need to provide some additional parameters. How much do you want to downsample? How many convolutional layers do you want?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dacapo.experiments.architectures import CNNectomeUNetConfig\n",
    "\n",
    "architecture_config = CNNectomeUNetConfig(\n",
    "    name=\"example_attention-upsample-unet\",\n",
    "    input_shape=(216, 216, 216),\n",
    "    fmaps_out=72,\n",
    "    fmaps_in=1,\n",
    "    num_fmaps=12,\n",
    "    fmap_inc_factor=6,\n",
    "    downsample_factors=[(2, 2, 2), (3, 3, 3), (3, 3, 3)],\n",
    "    kernel_size_down=None,\n",
    "    kernel_size_up=None,\n",
    "    eval_shape_increase=(72, 72, 72),\n",
    "    upsample_factors=[(2, 2, 2)],\n",
    "    constant_upsample=True,\n",
    "    padding=\"valid\",\n",
    "    use_attention=True,\n",
    ")\n",
    "config_store.store_architecture_config(architecture_config)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Trainer\n",
    "\n",
    "How do you want to train? This config defines the training loop and how the other three components work together. What sort of augmentations to apply during training, what learning rate and optimizer to use, what batch size to train with."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dacapo.experiments.trainers import GunpowderTrainerConfig\n",
    "from dacapo.experiments.trainers.gp_augments import (\n",
    "    ElasticAugmentConfig,\n",
    "    GammaAugmentConfig,\n",
    "    IntensityAugmentConfig,\n",
    "    IntensityScaleShiftAugmentConfig,\n",
    ")\n",
    "\n",
    "trainer_config = GunpowderTrainerConfig(\n",
    "    name=\"default\",\n",
    "    batch_size=2,\n",
    "    learning_rate=0.0001,\n",
    "    num_data_fetchers=20,\n",
    "    augments=[\n",
    "        ElasticAugmentConfig(\n",
    "            control_point_spacing=[100, 100, 100],\n",
    "            control_point_displacement_sigma=[10.0, 10.0, 10.0],\n",
    "            rotation_interval=(0.0, 1.5707963267948966),\n",
    "            subsample=8,\n",
    "            uniform_3d_rotation=True,\n",
    "        ),\n",
    "        IntensityAugmentConfig(scale=(0.25, 1.75), shift=(-0.5, 0.35), clip=True),\n",
    "        GammaAugmentConfig(gamma_range=(0.5, 2.0)),\n",
    "        IntensityScaleShiftAugmentConfig(scale=2.0, shift=-1.0),\n",
    "    ],\n",
    "    snapshot_interval=10000,\n",
    "    min_masked=0.05,\n",
    "    clip_raw=True,\n",
    ")\n",
    "config_store.store_trainer_config(trainer_config)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run\n",
    "Now that we have our components configured, we just need to combine them into a run and start training. We can have multiple repetitions of a single set of configs in order to increase our chances of finding an optimum."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dacapo.experiments.starts import StartConfig\n",
    "from dacapo.experiments import RunConfig\n",
    "from dacapo.experiments.run import Run\n",
    "\n",
    "start_config = None\n",
    "\n",
    "# Uncomment to start from a pretrained model\n",
    "# start_config = StartConfig(\n",
    "#     \"setup04\",\n",
    "#     \"best\",\n",
    "# )\n",
    "\n",
    "iterations = 200\n",
    "validation_interval = 5\n",
    "repetitions = 3\n",
    "for i in range(repetitions):\n",
    "    run_config = RunConfig(\n",
    "        name=(\"_\").join(\n",
    "            [\n",
    "                \"example\",\n",
    "                \"scratch\" if start_config is None else \"finetuned\",\n",
    "                datasplit_config.name,\n",
    "                task_config.name,\n",
    "                architecture_config.name,\n",
    "                trainer_config.name,\n",
    "            ]\n",
    "        )\n",
    "        + f\"__{i}\",\n",
    "        datasplit_config=datasplit_config,\n",
    "        task_config=task_config,\n",
    "        architecture_config=architecture_config,\n",
    "        trainer_config=trainer_config,\n",
    "        num_iterations=iterations,\n",
    "        validation_interval=validation_interval,\n",
    "        repetition=i,\n",
    "        start_config=start_config,\n",
    "    )\n",
    "\n",
    "    print(run_config.name)\n",
    "    config_store.store_run_config(run_config)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To train one of the runs, you can either do it by first creating a **Run** directly from the run config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dacapo.train import train_run\n",
    "\n",
    "run = Run(config_store.retrieve_run_config(run_config.name))\n",
    "train_run(run)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you want to start your run on some compute cluster, you might want to use the command line interface: dacapo train -r {run_config.name}. This makes it particularly convenient to run on compute nodes where you can specify specific compute requirements."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.ndimage import (\n",
    "    distance_transform_edt,\n",
    "    binary_dilation,\n",
    "    generate_binary_structure,\n",
    ")\n",
    "import numpy as np\n",
    "from skimage.measure import label as relabel\n",
    "\n",
    "labels = np.zeros((512, 512, 512), dtype=np.uint8)\n",
    "generate_binary_structure(3, connectivity=2)\n",
    "\n",
    "random_point_centers = np.random.randint(1, 255, (250, 3))\n",
    "\n",
    "labels[random_point_centers] = 1\n",
    "generate_binary_structure(3, connectivity=2)\n",
    "labels = binary_dilation(labels)\n",
    "\n",
    "relabeled = relabel(labels, connectivity=2).astype(labels.dtype)  # type: ignore\n",
    "relabeled = relabel(relabeled, connectivity=2).astype(labels.dtype)  # type: ignore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "generate_binary_structure(3, connectivity=2)\n",
    "binary_dilation(arr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import neuroglancer\n",
    "from funlib.persistence import open_ds\n",
    "import numpy as np\n",
    "from IPython.display import IFrame\n",
    "\n",
    "voxel_size = (8, 8, 8)\n",
    "neuroglancer.set_server_bind_address(\"0.0.0.0\")\n",
    "viewer = neuroglancer.Viewer()\n",
    "raw = open_ds(\"./tmp/validation.zarr\", \"RAW\")\n",
    "labels = open_ds(\"./tmp/validation.zarr\", \"LABELS\")\n",
    "labels_data = labels.to_ndarray()\n",
    "\n",
    "with viewer.txn() as state:\n",
    "    state.showSlices = False\n",
    "    state.layers[\"segs\"] = neuroglancer.SegmentationLayer(\n",
    "        # segments=[str(i) for i in np.unique(data[data > 0])], # this line will cause all objects to be selected and thus all meshes to be generated...will be slow if lots of high res meshes\n",
    "        source=neuroglancer.LocalVolume(\n",
    "            data=labels_data,\n",
    "            dimensions=neuroglancer.CoordinateSpace(\n",
    "                names=[\"z\", \"y\", \"x\"],\n",
    "                units=[\"nm\", \"nm\", \"nm\"],\n",
    "                scales=labels.voxel_size,\n",
    "            ),\n",
    "            # voxel_offset=ds.roi.begin / ds.voxel_size,\n",
    "        ),\n",
    "        segments=np.unique(labels_data[labels_data > 0]),\n",
    "    )\n",
    "\n",
    "    state.layers[\"raw\"] = neuroglancer.ImageLayer(\n",
    "        source=neuroglancer.LocalVolume(\n",
    "            data=raw.data,\n",
    "            dimensions=neuroglancer.CoordinateSpace(\n",
    "                names=[\"z\", \"y\", \"x\"],\n",
    "                units=[\"nm\", \"nm\", \"nm\"],\n",
    "                scales=raw.voxel_size,\n",
    "            ),\n",
    "        ),\n",
    "    )\n",
    "IFrame(src=viewer, width=1800, height=900)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# View run"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## neuroglancer run viewer class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating FileConfigStore:\n",
      "\tpath: /nrs/cellmap/ackermand/dacapo_learnathon_examples/configs\n"
     ]
    }
   ],
   "source": [
    "from funlib.persistence import open_ds\n",
    "from threading import Thread\n",
    "import neuroglancer\n",
    "from neuroglancer.viewer_state import ViewerState\n",
    "import os\n",
    "from dacapo.experiments.run import Run\n",
    "from dacapo.store.create_store import create_config_store, create_array_store\n",
    "from IPython.display import IFrame\n",
    "import time\n",
    "import copy\n",
    "import json\n",
    "\n",
    "config_store = create_config_store()\n",
    "run_name = \"example_scratch_example_synthetic_datasplit_config_example_synthetic_distance_task_config_example_synthetic_unet_example_synthetic_trainer_config__0\"\n",
    "run = Run(config_store.retrieve_run_config(run_name))\n",
    "\n",
    "\n",
    "class NeuroglancerRunViewer:\n",
    "    def __init__(self, run):\n",
    "        self.run: Run = run\n",
    "        self.most_recent_iteration = 0\n",
    "        self.prediction = None\n",
    "\n",
    "    def updated_neuroglancer_layer(self, layer_name, ds):\n",
    "        source = neuroglancer.LocalVolume(\n",
    "            data=ds.data,\n",
    "            dimensions=neuroglancer.CoordinateSpace(\n",
    "                names=[\"c\", \"z\", \"y\", \"x\"],\n",
    "                units=[\"\", \"nm\", \"nm\", \"nm\"],\n",
    "                scales=[1] + list(ds.voxel_size),\n",
    "            ),\n",
    "            voxel_offset=[0] + list(ds.roi.offset),\n",
    "        )\n",
    "        new_state = copy.deepcopy(self.viewer.state)\n",
    "        if len(new_state.layers) == 1:\n",
    "            new_state.layers[layer_name] = neuroglancer.ImageLayer(source=source)\n",
    "        else:\n",
    "            # replace name everywhere to preserve state, like what is selected\n",
    "            new_state_str = json.dumps(new_state.to_json())\n",
    "            new_state_str = new_state_str.replace(new_state.layers[-1].name, layer_name)\n",
    "            new_state = ViewerState(json.loads(new_state_str))\n",
    "            new_state.layers[layer_name].source = source\n",
    "\n",
    "        self.viewer.set_state(new_state)\n",
    "        print(self.viewer.state)\n",
    "\n",
    "    def deprecated_start_neuroglancer(self):\n",
    "        neuroglancer.set_server_bind_address(\"0.0.0.0\")\n",
    "        self.viewer = neuroglancer.Viewer()\n",
    "\n",
    "    def start_neuroglancer(self):\n",
    "        neuroglancer.set_server_bind_address(\"0.0.0.0\")\n",
    "        self.viewer = neuroglancer.Viewer()\n",
    "        # raw = open_ds(\"./tmp/validation.zarr\", \"RAW\")\n",
    "        # labels = open_ds(\"./tmp/validation.zarr\", \"LABELS\")\n",
    "        # labels_data = labels.to_ndarray()\n",
    "        with self.viewer.txn() as state:\n",
    "            state.showSlices = False\n",
    "\n",
    "            state.layers[\"raw\"] = neuroglancer.ImageLayer(\n",
    "                source=neuroglancer.LocalVolume(\n",
    "                    data=self.raw.data,\n",
    "                    dimensions=neuroglancer.CoordinateSpace(\n",
    "                        names=[\"z\", \"y\", \"x\"],\n",
    "                        units=[\"nm\", \"nm\", \"nm\"],\n",
    "                        scales=self.raw.voxel_size,\n",
    "                    ),\n",
    "                    voxel_offset=self.raw.roi.offset,\n",
    "                ),\n",
    "            )\n",
    "        return IFrame(src=self.viewer, width=1800, height=900)\n",
    "\n",
    "    def start(self):\n",
    "        self.array_store = create_array_store()\n",
    "        self.get_datasets()\n",
    "        self.new_validation_checker()\n",
    "        return self.start_neuroglancer()\n",
    "\n",
    "    def open_from_array_identitifier(self, array_identifier):\n",
    "        if os.path.exists(array_identifier.container / array_identifier.dataset):\n",
    "            return open_ds(str(array_identifier.container), array_identifier.dataset)\n",
    "        else:\n",
    "            return None\n",
    "\n",
    "    def get_datasets(self):\n",
    "        for validation_dataset in self.run.datasplit.validate:\n",
    "            (\n",
    "                input_raw_array_identifier,\n",
    "                input_gt_array_identifier,\n",
    "            ) = self.array_store.validation_input_arrays(\n",
    "                self.run.name, validation_dataset.name\n",
    "            )\n",
    "\n",
    "            self.raw = self.open_from_array_identitifier(input_raw_array_identifier)\n",
    "            self.gt = self.open_from_array_identitifier(input_gt_array_identifier)\n",
    "        print(self.raw)\n",
    "\n",
    "    def update_best_info(self, iteration, validation_dataset_name):\n",
    "        prediction_array_identifier = self.array_store.validation_prediction_array(\n",
    "            self.run.name,\n",
    "            iteration,\n",
    "            validation_dataset_name,\n",
    "        )\n",
    "        self.prediction = self.open_from_array_identitifier(prediction_array_identifier)\n",
    "        self.most_recent_iteration = iteration\n",
    "\n",
    "    def update_neuroglancer(self, iteration):\n",
    "        self.updated_neuroglancer_layer(\n",
    "            f\"prediction at iteration {iteration}\", self.prediction\n",
    "        )\n",
    "        return None\n",
    "\n",
    "    def update_best(self, iteration, validation_dataset_name):\n",
    "        self.update_best_info(iteration, validation_dataset_name)\n",
    "        self.update_neuroglancer(iteration)\n",
    "\n",
    "    def new_validation_checker(self):\n",
    "        self.process = Thread(  # multiprocessing.Process(\n",
    "            target=self.update_with_new_validation_if_possible\n",
    "        )\n",
    "        self.process.daemon = True\n",
    "        self.process.start()\n",
    "\n",
    "    def update_with_new_validation_if_possible(self):\n",
    "        while True:\n",
    "            time.sleep(3)\n",
    "            for validation_dataset in self.run.datasplit.validate:\n",
    "                most_recent_iteration_previous = self.most_recent_iteration\n",
    "                prediction_array_identifier = (\n",
    "                    self.array_store.validation_prediction_array(\n",
    "                        self.run.name,\n",
    "                        self.most_recent_iteration,\n",
    "                        validation_dataset.name,\n",
    "                    )\n",
    "                )\n",
    "\n",
    "                container = prediction_array_identifier.container\n",
    "                if os.path.exists(container):\n",
    "                    iteration_dirs = [\n",
    "                        name\n",
    "                        for name in os.listdir(container)\n",
    "                        if os.path.isdir(os.path.join(container, name))\n",
    "                        and name.isnumeric()\n",
    "                    ]\n",
    "\n",
    "                    for iteration_dir in iteration_dirs:\n",
    "                        if int(iteration_dir) > self.most_recent_iteration:\n",
    "                            inference_dir = os.path.join(\n",
    "                                container,\n",
    "                                iteration_dir,\n",
    "                                \"validation_config\",\n",
    "                                \"prediction\",\n",
    "                            )\n",
    "                            if os.path.exists(inference_dir):\n",
    "                                inference_dir_contents = [\n",
    "                                    f\n",
    "                                    for f in os.listdir(inference_dir)\n",
    "                                    if not f.startswith(\".\") and not f.endswith(\".json\")\n",
    "                                ]\n",
    "                                if inference_dir_contents:\n",
    "                                    # then it should have at least a chunk writtent out, assume it has all of it written out\n",
    "                                    self.most_recent_iteration = int(iteration_dir)\n",
    "                    if most_recent_iteration_previous != self.most_recent_iteration:\n",
    "                        self.update_best(\n",
    "                            self.most_recent_iteration,\n",
    "                            validation_dataset.name,\n",
    "                        )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# set up neuroglancer that tracks progress"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nrv = NeuroglancerRunViewer(run)\n",
    "nrv.start()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# pseudo training, really now just does inference very few seconds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating FileConfigStore:\n",
      "\tpath: /nrs/cellmap/ackermand/dacapo_learnathon_examples/configs\n",
      "Creating local weights store in directory %s /nrs/cellmap/ackermand/dacapo_learnathon_examples\n",
      "hi\n",
      "hi\n",
      "hi\n",
      "hi\n",
      "hi\n",
      "hi\n",
      "hi\n",
      "hi\n",
      "hi\n",
      "hi\n",
      "hi\n",
      "hi\n",
      "hi\n",
      "hi\n",
      "hi\n",
      "hi\n",
      "hi\n",
      "hi\n",
      "hi\n",
      "hi\n",
      "hi\n",
      "hi\n",
      "hi\n",
      "hi\n",
      "hi\n",
      "hi\n",
      "hi\n",
      "hi\n",
      "hi\n",
      "hi\n",
      "hi\n",
      "hi\n",
      "hi\n",
      "hi\n",
      "hi\n",
      "hi\n",
      "hi\n",
      "hi\n",
      "hi\n",
      "hi\n",
      "hi\n",
      "hi\n",
      "hi\n",
      "hi\n",
      "hi\n",
      "hi\n",
      "hi\n",
      "hi\n",
      "hi\n"
     ]
    }
   ],
   "source": [
    "from old_predict import predict\n",
    "from dacapo.experiments.run import Run\n",
    "from funlib.geometry import Roi\n",
    "import shutil\n",
    "from dacapo.store.create_store import (\n",
    "    create_config_store,\n",
    "    create_array_store,\n",
    "    create_weights_store,\n",
    ")\n",
    "\n",
    "config_store = create_config_store()\n",
    "array_store = create_array_store()\n",
    "run_name = \"example_scratch_example_synthetic_datasplit_config_example_synthetic_distance_task_config_example_synthetic_unet_example_synthetic_trainer_config__0\"\n",
    "run = Run(config_store.retrieve_run_config(run_name))\n",
    "# create weights store and read weights\n",
    "weights_store = create_weights_store()\n",
    "for iteration in range(50, 2500, 50):\n",
    "    print(\"hi\")\n",
    "    # time.sleep(3)\n",
    "    #shutil.rmtree(f\"/nrs/cellmap/ackermand/dacapo_learnathon_examples/{run_name}/validation.zarr/{iteration}/validation_config/prediction\")\n",
    "    # weights = weights_store.retrieve_weights(run, iteration)\n",
    "    # run.model.load_state_dict(weights.model)\n",
    "    # prediction_array_identifier = array_store.validation_prediction_array(\n",
    "    #     run.name, iteration, run.datasplit.validate[0].name\n",
    "    # )\n",
    "    # # predict(run.model, run.datasplit.validate[0].raw, prediction_array_identifier)\n",
    "    # # %%\n",
    "\n",
    "    # predict(\n",
    "    #     run.model,\n",
    "    #     run.datasplit.validate[0].raw,\n",
    "    #     prediction_array_identifier,\n",
    "    #     output_roi=Roi((0, 0, 0), (864, 864, 864)),\n",
    "    # )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dacapo",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
